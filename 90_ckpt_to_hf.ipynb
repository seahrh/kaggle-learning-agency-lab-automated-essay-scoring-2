{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7482808b-c292-4843-9dae-951ff5560b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import scml\n",
    "from scml import pandasx as pdx\n",
    "from lalaes2 import Aes2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7749a540-0233-47f9-ac3b-5a832b6a5036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int16, min=-32768, max=32767\n",
      "device=0, NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n",
      "device=1, NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()\n",
    "info = np.iinfo(np.int16)\n",
    "print(f\"int16, min={info.min}, max={info.max}\")\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"device={i}, {torch.cuda.get_device_name(i)}\")\n",
    "        print('Mem Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n",
    "        print('Mem Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')\n",
    "else:\n",
    "    print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d76be417-30e7-48e2-ae52-5ccd7cd8c0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])\n"
     ]
    }
   ],
   "source": [
    "dst_path = Path(\"models/aes2/deberta_v3_base/20240615_063400\")\n",
    "ckpt_path = dst_path / \"lightning_logs/version_0/checkpoints/epoch=3-step=2004-val_loss=0.31256.ckpt\"\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2cdb63d-a5d8-4122-846a-8ed47800da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pretrained_dir': '/mnt/c/huggingface/microsoft/deberta-v3-base', 'lr': 1e-05, 'scheduler_conf': [<Section: reduce_lr_on_plateau>], 'model_class': 'auto', 'swa_start_epoch': -1, 'gradient_checkpointing': False, 'hidden_dropout_prob': 0.0, 'attention_probs_dropout_prob': 0.0, 'max_position_embeddings': 512}\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint[\"hyper_parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da7bcd1d-6684-4633-8d1a-67c1f3c6732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['model.deberta.embeddings.word_embeddings.weight', 'model.deberta.embeddings.LayerNorm.weight', 'model.deberta.embeddings.LayerNorm.bias', 'model.deberta.encoder.layer.0.attention.self.query_proj.weight', 'model.deberta.encoder.layer.0.attention.self.query_proj.bias', 'model.deberta.encoder.layer.0.attention.self.key_proj.weight', 'model.deberta.encoder.layer.0.attention.self.key_proj.bias', 'model.deberta.encoder.layer.0.attention.self.value_proj.weight', 'model.deberta.encoder.layer.0.attention.self.value_proj.bias', 'model.deberta.encoder.layer.0.attention.output.dense.weight', 'model.deberta.encoder.layer.0.attention.output.dense.bias', 'model.deberta.encoder.layer.0.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.0.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.0.intermediate.dense.weight', 'model.deberta.encoder.layer.0.intermediate.dense.bias', 'model.deberta.encoder.layer.0.output.dense.weight', 'model.deberta.encoder.layer.0.output.dense.bias', 'model.deberta.encoder.layer.0.output.LayerNorm.weight', 'model.deberta.encoder.layer.0.output.LayerNorm.bias', 'model.deberta.encoder.layer.1.attention.self.query_proj.weight', 'model.deberta.encoder.layer.1.attention.self.query_proj.bias', 'model.deberta.encoder.layer.1.attention.self.key_proj.weight', 'model.deberta.encoder.layer.1.attention.self.key_proj.bias', 'model.deberta.encoder.layer.1.attention.self.value_proj.weight', 'model.deberta.encoder.layer.1.attention.self.value_proj.bias', 'model.deberta.encoder.layer.1.attention.output.dense.weight', 'model.deberta.encoder.layer.1.attention.output.dense.bias', 'model.deberta.encoder.layer.1.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.1.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.1.intermediate.dense.weight', 'model.deberta.encoder.layer.1.intermediate.dense.bias', 'model.deberta.encoder.layer.1.output.dense.weight', 'model.deberta.encoder.layer.1.output.dense.bias', 'model.deberta.encoder.layer.1.output.LayerNorm.weight', 'model.deberta.encoder.layer.1.output.LayerNorm.bias', 'model.deberta.encoder.layer.2.attention.self.query_proj.weight', 'model.deberta.encoder.layer.2.attention.self.query_proj.bias', 'model.deberta.encoder.layer.2.attention.self.key_proj.weight', 'model.deberta.encoder.layer.2.attention.self.key_proj.bias', 'model.deberta.encoder.layer.2.attention.self.value_proj.weight', 'model.deberta.encoder.layer.2.attention.self.value_proj.bias', 'model.deberta.encoder.layer.2.attention.output.dense.weight', 'model.deberta.encoder.layer.2.attention.output.dense.bias', 'model.deberta.encoder.layer.2.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.2.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.2.intermediate.dense.weight', 'model.deberta.encoder.layer.2.intermediate.dense.bias', 'model.deberta.encoder.layer.2.output.dense.weight', 'model.deberta.encoder.layer.2.output.dense.bias', 'model.deberta.encoder.layer.2.output.LayerNorm.weight', 'model.deberta.encoder.layer.2.output.LayerNorm.bias', 'model.deberta.encoder.layer.3.attention.self.query_proj.weight', 'model.deberta.encoder.layer.3.attention.self.query_proj.bias', 'model.deberta.encoder.layer.3.attention.self.key_proj.weight', 'model.deberta.encoder.layer.3.attention.self.key_proj.bias', 'model.deberta.encoder.layer.3.attention.self.value_proj.weight', 'model.deberta.encoder.layer.3.attention.self.value_proj.bias', 'model.deberta.encoder.layer.3.attention.output.dense.weight', 'model.deberta.encoder.layer.3.attention.output.dense.bias', 'model.deberta.encoder.layer.3.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.3.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.3.intermediate.dense.weight', 'model.deberta.encoder.layer.3.intermediate.dense.bias', 'model.deberta.encoder.layer.3.output.dense.weight', 'model.deberta.encoder.layer.3.output.dense.bias', 'model.deberta.encoder.layer.3.output.LayerNorm.weight', 'model.deberta.encoder.layer.3.output.LayerNorm.bias', 'model.deberta.encoder.layer.4.attention.self.query_proj.weight', 'model.deberta.encoder.layer.4.attention.self.query_proj.bias', 'model.deberta.encoder.layer.4.attention.self.key_proj.weight', 'model.deberta.encoder.layer.4.attention.self.key_proj.bias', 'model.deberta.encoder.layer.4.attention.self.value_proj.weight', 'model.deberta.encoder.layer.4.attention.self.value_proj.bias', 'model.deberta.encoder.layer.4.attention.output.dense.weight', 'model.deberta.encoder.layer.4.attention.output.dense.bias', 'model.deberta.encoder.layer.4.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.4.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.4.intermediate.dense.weight', 'model.deberta.encoder.layer.4.intermediate.dense.bias', 'model.deberta.encoder.layer.4.output.dense.weight', 'model.deberta.encoder.layer.4.output.dense.bias', 'model.deberta.encoder.layer.4.output.LayerNorm.weight', 'model.deberta.encoder.layer.4.output.LayerNorm.bias', 'model.deberta.encoder.layer.5.attention.self.query_proj.weight', 'model.deberta.encoder.layer.5.attention.self.query_proj.bias', 'model.deberta.encoder.layer.5.attention.self.key_proj.weight', 'model.deberta.encoder.layer.5.attention.self.key_proj.bias', 'model.deberta.encoder.layer.5.attention.self.value_proj.weight', 'model.deberta.encoder.layer.5.attention.self.value_proj.bias', 'model.deberta.encoder.layer.5.attention.output.dense.weight', 'model.deberta.encoder.layer.5.attention.output.dense.bias', 'model.deberta.encoder.layer.5.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.5.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.5.intermediate.dense.weight', 'model.deberta.encoder.layer.5.intermediate.dense.bias', 'model.deberta.encoder.layer.5.output.dense.weight', 'model.deberta.encoder.layer.5.output.dense.bias', 'model.deberta.encoder.layer.5.output.LayerNorm.weight', 'model.deberta.encoder.layer.5.output.LayerNorm.bias', 'model.deberta.encoder.layer.6.attention.self.query_proj.weight', 'model.deberta.encoder.layer.6.attention.self.query_proj.bias', 'model.deberta.encoder.layer.6.attention.self.key_proj.weight', 'model.deberta.encoder.layer.6.attention.self.key_proj.bias', 'model.deberta.encoder.layer.6.attention.self.value_proj.weight', 'model.deberta.encoder.layer.6.attention.self.value_proj.bias', 'model.deberta.encoder.layer.6.attention.output.dense.weight', 'model.deberta.encoder.layer.6.attention.output.dense.bias', 'model.deberta.encoder.layer.6.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.6.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.6.intermediate.dense.weight', 'model.deberta.encoder.layer.6.intermediate.dense.bias', 'model.deberta.encoder.layer.6.output.dense.weight', 'model.deberta.encoder.layer.6.output.dense.bias', 'model.deberta.encoder.layer.6.output.LayerNorm.weight', 'model.deberta.encoder.layer.6.output.LayerNorm.bias', 'model.deberta.encoder.layer.7.attention.self.query_proj.weight', 'model.deberta.encoder.layer.7.attention.self.query_proj.bias', 'model.deberta.encoder.layer.7.attention.self.key_proj.weight', 'model.deberta.encoder.layer.7.attention.self.key_proj.bias', 'model.deberta.encoder.layer.7.attention.self.value_proj.weight', 'model.deberta.encoder.layer.7.attention.self.value_proj.bias', 'model.deberta.encoder.layer.7.attention.output.dense.weight', 'model.deberta.encoder.layer.7.attention.output.dense.bias', 'model.deberta.encoder.layer.7.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.7.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.7.intermediate.dense.weight', 'model.deberta.encoder.layer.7.intermediate.dense.bias', 'model.deberta.encoder.layer.7.output.dense.weight', 'model.deberta.encoder.layer.7.output.dense.bias', 'model.deberta.encoder.layer.7.output.LayerNorm.weight', 'model.deberta.encoder.layer.7.output.LayerNorm.bias', 'model.deberta.encoder.layer.8.attention.self.query_proj.weight', 'model.deberta.encoder.layer.8.attention.self.query_proj.bias', 'model.deberta.encoder.layer.8.attention.self.key_proj.weight', 'model.deberta.encoder.layer.8.attention.self.key_proj.bias', 'model.deberta.encoder.layer.8.attention.self.value_proj.weight', 'model.deberta.encoder.layer.8.attention.self.value_proj.bias', 'model.deberta.encoder.layer.8.attention.output.dense.weight', 'model.deberta.encoder.layer.8.attention.output.dense.bias', 'model.deberta.encoder.layer.8.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.8.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.8.intermediate.dense.weight', 'model.deberta.encoder.layer.8.intermediate.dense.bias', 'model.deberta.encoder.layer.8.output.dense.weight', 'model.deberta.encoder.layer.8.output.dense.bias', 'model.deberta.encoder.layer.8.output.LayerNorm.weight', 'model.deberta.encoder.layer.8.output.LayerNorm.bias', 'model.deberta.encoder.layer.9.attention.self.query_proj.weight', 'model.deberta.encoder.layer.9.attention.self.query_proj.bias', 'model.deberta.encoder.layer.9.attention.self.key_proj.weight', 'model.deberta.encoder.layer.9.attention.self.key_proj.bias', 'model.deberta.encoder.layer.9.attention.self.value_proj.weight', 'model.deberta.encoder.layer.9.attention.self.value_proj.bias', 'model.deberta.encoder.layer.9.attention.output.dense.weight', 'model.deberta.encoder.layer.9.attention.output.dense.bias', 'model.deberta.encoder.layer.9.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.9.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.9.intermediate.dense.weight', 'model.deberta.encoder.layer.9.intermediate.dense.bias', 'model.deberta.encoder.layer.9.output.dense.weight', 'model.deberta.encoder.layer.9.output.dense.bias', 'model.deberta.encoder.layer.9.output.LayerNorm.weight', 'model.deberta.encoder.layer.9.output.LayerNorm.bias', 'model.deberta.encoder.layer.10.attention.self.query_proj.weight', 'model.deberta.encoder.layer.10.attention.self.query_proj.bias', 'model.deberta.encoder.layer.10.attention.self.key_proj.weight', 'model.deberta.encoder.layer.10.attention.self.key_proj.bias', 'model.deberta.encoder.layer.10.attention.self.value_proj.weight', 'model.deberta.encoder.layer.10.attention.self.value_proj.bias', 'model.deberta.encoder.layer.10.attention.output.dense.weight', 'model.deberta.encoder.layer.10.attention.output.dense.bias', 'model.deberta.encoder.layer.10.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.10.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.10.intermediate.dense.weight', 'model.deberta.encoder.layer.10.intermediate.dense.bias', 'model.deberta.encoder.layer.10.output.dense.weight', 'model.deberta.encoder.layer.10.output.dense.bias', 'model.deberta.encoder.layer.10.output.LayerNorm.weight', 'model.deberta.encoder.layer.10.output.LayerNorm.bias', 'model.deberta.encoder.layer.11.attention.self.query_proj.weight', 'model.deberta.encoder.layer.11.attention.self.query_proj.bias', 'model.deberta.encoder.layer.11.attention.self.key_proj.weight', 'model.deberta.encoder.layer.11.attention.self.key_proj.bias', 'model.deberta.encoder.layer.11.attention.self.value_proj.weight', 'model.deberta.encoder.layer.11.attention.self.value_proj.bias', 'model.deberta.encoder.layer.11.attention.output.dense.weight', 'model.deberta.encoder.layer.11.attention.output.dense.bias', 'model.deberta.encoder.layer.11.attention.output.LayerNorm.weight', 'model.deberta.encoder.layer.11.attention.output.LayerNorm.bias', 'model.deberta.encoder.layer.11.intermediate.dense.weight', 'model.deberta.encoder.layer.11.intermediate.dense.bias', 'model.deberta.encoder.layer.11.output.dense.weight', 'model.deberta.encoder.layer.11.output.dense.bias', 'model.deberta.encoder.layer.11.output.LayerNorm.weight', 'model.deberta.encoder.layer.11.output.LayerNorm.bias', 'model.deberta.encoder.rel_embeddings.weight', 'model.deberta.encoder.LayerNorm.weight', 'model.deberta.encoder.LayerNorm.bias', 'model.pooler.dense.weight', 'model.pooler.dense.bias', 'model.classifier.weight', 'model.classifier.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint[\"state_dict\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "787be70c-d2e0-4d62-b27b-c12efb83e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|aes2.py:207] 2024-06-15 08:43:00,162 >> config.to_diff_dict={\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"_name_or_path\": \"/mnt/c/huggingface/microsoft/deberta-v3-base\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"position_buckets\": 256,\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"share_att_key\": true,\n",
      "  \"hidden_size\": 768,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"relative_attention\": true,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"position_biased_input\": false,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"vocab_size\": 128100,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"gradient_checkpointing\": false\n",
      "}\n",
      "[INFO|aes2.py:207] 2024-06-15 08:43:00,162 >> config.to_diff_dict={\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"_name_or_path\": \"/mnt/c/huggingface/microsoft/deberta-v3-base\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"position_buckets\": 256,\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"share_att_key\": true,\n",
      "  \"hidden_size\": 768,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"relative_attention\": true,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"position_biased_input\": false,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"vocab_size\": 128100,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"gradient_checkpointing\": false\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /mnt/c/huggingface/microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.46 s, sys: 1.38 s, total: 10.8 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Aes2Model.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25fb6425-7dd8-4442-b491-37a67661af5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 920 ms, sys: 177 ms, total: 1.1 s\n",
      "Wall time: 3.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.model.save_pretrained(str(dst_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00a9f885-a93f-45c9-8a65-dca654af7ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2ForSequenceClassification(\n",
      "  (deberta): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pooler): ContextPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): StableDropout()\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (dropout): StableDropout()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c363b3f8-51b7-42f8-a917-b654fe2a3d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:00:25.847133\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
