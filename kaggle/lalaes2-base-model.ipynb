{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55436d5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:13:38.917345Z",
     "iopub.status.busy": "2024-07-02T15:13:38.917073Z",
     "iopub.status.idle": "2024-07-02T15:14:30.466890Z",
     "shell.execute_reply": "2024-07-02T15:14:30.465948Z"
    },
    "papermill": {
     "duration": 51.559968,
     "end_time": "2024-07-02T15:14:30.469390",
     "exception": false,
     "start_time": "2024-07-02T15:13:38.909422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pip-wheels/scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "Successfully installed scikit-learn-1.5.0\r\n",
      "Processing /kaggle/input/pip-wheels/bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl\r\n",
      "Installing collected packages: bitsandbytes\r\n",
      "Successfully installed bitsandbytes-0.43.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --no-deps --force-reinstall /kaggle/input/pip-wheels/scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install --upgrade --no-deps --force-reinstall /kaggle/input/pip-wheels/bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69d1f0f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-02T15:14:30.485013Z",
     "iopub.status.busy": "2024-07-02T15:14:30.484675Z",
     "iopub.status.idle": "2024-07-02T15:14:37.051410Z",
     "shell.execute_reply": "2024-07-02T15:14:37.050488Z"
    },
    "papermill": {
     "duration": 6.577009,
     "end_time": "2024-07-02T15:14:37.053659",
     "exception": false,
     "start_time": "2024-07-02T15:14:30.476650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==1.5.0, bitsandbytes==0.43.1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import re\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import jinja2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import bitsandbytes\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, NamedTuple, Callable, Iterable, Set, Optional, Any\n",
    "print(f\"scikit-learn=={sklearn.__version__}, bitsandbytes=={bitsandbytes.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9307212e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:14:37.069212Z",
     "iopub.status.busy": "2024-07-02T15:14:37.068762Z",
     "iopub.status.idle": "2024-07-02T15:14:37.083559Z",
     "shell.execute_reply": "2024-07-02T15:14:37.082653Z"
    },
    "papermill": {
     "duration": 0.025116,
     "end_time": "2024-07-02T15:14:37.085771",
     "exception": false,
     "start_time": "2024-07-02T15:14:37.060655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf(debug=False, input_dir=PosixPath('/kaggle/input'), comp_dir=PosixPath('/kaggle/input/learning-agency-lab-automated-essay-scoring-2'), temp_dir=PosixPath('/kaggle/temp'), working_dir=PosixPath('/kaggle/working'), resource_dir=PosixPath('/kaggle/input/lib-lalaes2/lalaes2-0.1'), data_dir=PosixPath('/kaggle/input/lib-lalaes2/lalaes2-0.1/input'), template_version=3, llm_key='gemma', llm_map={'qwen2': ModelConf(name='qwen2', directory=PosixPath('/kaggle/input/qwen2/transformers/qwen2-1.5b-instruct/1'), model_max_length=8192, batch_size=16, char_limit=4000, load_in_dtype='fp16'), 'gemma': ModelConf(name='gemma', directory=PosixPath('/kaggle/input/gemma/transformers/1.1-2b-it/1'), model_max_length=8192, batch_size=16, char_limit=4000, load_in_dtype='fp16'), 'phi2': ModelConf(name='phi2', directory=PosixPath('/kaggle/input/phi/transformers/2/1'), model_max_length=2048, batch_size=16, char_limit=4000, load_in_dtype='fp16'), 'mistral7b': ModelConf(name='mistral7b', directory=PosixPath('/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1'), model_max_length=4096, batch_size=16, char_limit=1000, load_in_dtype='auto'), 'mixtral8x7b': ModelConf(name='mixtral8x7b', directory=PosixPath('/kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1'), model_max_length=4096, batch_size=16, char_limit=1000, load_in_dtype='auto'), 'mixtral7b02': ModelConf(name='mixtral7b02', directory=PosixPath('/kaggle/input/mistral-7b-instruct-v02-fp16'), model_max_length=4096, batch_size=16, char_limit=1000, load_in_dtype='auto'), 'llama38b': ModelConf(name='llama38b', directory=PosixPath('/kaggle/input/llama-3/transformers/8b-hf/1'), model_max_length=8192, batch_size=16, char_limit=1000, load_in_dtype='auto'), 'llama38bchat': ModelConf(name='llama38bchat', directory=PosixPath('/kaggle/input/llama-3/transformers/8b-chat-hf/1'), model_max_length=8192, batch_size=16, char_limit=1000, load_in_dtype='auto')}, models=[ModelConf(name='deberta', directory=PosixPath('/kaggle/input/lib-lalaes2/lalaes2-0.1/models/aes2/deberta_v3_large/20240629_143241'), model_max_length=1280, batch_size=16, char_limit=1000, load_in_dtype='auto')], thresholds=[1.668159504388556, 2.309778795006449, 3.002342870933531, 4.3425596543567, 6.027380459922358])\n"
     ]
    }
   ],
   "source": [
    "class ModelConf(NamedTuple):\n",
    "    name: str\n",
    "    directory: Path\n",
    "    model_max_length: int = 512\n",
    "    batch_size: int = 16\n",
    "    char_limit: int = 1000\n",
    "    load_in_dtype: str = \"auto\"\n",
    "        \n",
    "\n",
    "class Conf(NamedTuple):\n",
    "    debug: bool = False  \n",
    "    input_dir: Path = Path(\"/kaggle/input\")\n",
    "    comp_dir: Path = input_dir / \"learning-agency-lab-automated-essay-scoring-2\"\n",
    "    temp_dir: Path = Path('/kaggle/temp')\n",
    "    # write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "    working_dir: Path = Path('/kaggle/working')\n",
    "    resource_dir: Path = input_dir / \"lib-lalaes2/lalaes2-0.1\"\n",
    "    data_dir: Path = resource_dir / \"input\"\n",
    "    template_version: int = 3\n",
    "    llm_key: str = \"gemma\"\n",
    "    llm_map: Dict[str, ModelConf] = {\n",
    "        \"qwen2\": ModelConf(\n",
    "            name=\"qwen2\",\n",
    "            directory = input_dir / \"qwen2/transformers/qwen2-1.5b-instruct/1\",\n",
    "            model_max_length=8192,\n",
    "            char_limit=4000,\n",
    "            load_in_dtype=\"fp16\",  # required for older gpus like P100,T4\n",
    "        ),\n",
    "        \"gemma\": ModelConf(\n",
    "            name=\"gemma\",\n",
    "            directory = input_dir / \"gemma/transformers/1.1-2b-it/1\",\n",
    "            model_max_length=8192,\n",
    "            char_limit=4000,\n",
    "            load_in_dtype=\"fp16\",\n",
    "        ),\n",
    "        \"phi2\": ModelConf(\n",
    "            name=\"phi2\",\n",
    "            directory = input_dir / \"phi/transformers/2/1\",\n",
    "            model_max_length=2048,\n",
    "            char_limit=4000,\n",
    "            load_in_dtype=\"fp16\",\n",
    "        ),\n",
    "        \"mistral7b\": ModelConf(\n",
    "            name=\"mistral7b\",\n",
    "            directory = input_dir / \"mistral/pytorch/7b-instruct-v0.1-hf/1\",\n",
    "            model_max_length=4096,\n",
    "            char_limit=1000,\n",
    "        ),\n",
    "        \"mixtral8x7b\": ModelConf(\n",
    "            name=\"mixtral8x7b\",\n",
    "            directory = input_dir / \"mixtral/pytorch/8x7b-instruct-v0.1-hf/1\",\n",
    "            model_max_length=4096,\n",
    "            char_limit=1000,\n",
    "        ),\n",
    "        \"mixtral7b02\": ModelConf(\n",
    "            name=\"mixtral7b02\",\n",
    "            directory = input_dir / \"mistral-7b-instruct-v02-fp16\",\n",
    "            model_max_length=4096,\n",
    "            char_limit=1000,\n",
    "        ),\n",
    "        \"llama38b\": ModelConf(\n",
    "            name=\"llama38b\",\n",
    "            directory = input_dir / \"llama-3/transformers/8b-hf/1\",\n",
    "            model_max_length=8192,\n",
    "            char_limit=1000,\n",
    "        ),\n",
    "        \"llama38bchat\": ModelConf(\n",
    "            name=\"llama38bchat\",\n",
    "            directory = input_dir / \"llama-3/transformers/8b-chat-hf/1\",\n",
    "            model_max_length=8192,\n",
    "            char_limit=1000,\n",
    "        ),\n",
    "    }\n",
    "    models: List[ModelConf] = [\n",
    "        ModelConf(\n",
    "            name=\"deberta\",\n",
    "            directory=resource_dir / \"models/aes2/deberta_v3_large/20240629_143241\",\n",
    "            model_max_length=1280,\n",
    "            batch_size=16,\n",
    "        ),\n",
    "    ]\n",
    "    thresholds: List[float] = [\n",
    "        1.668159504388556,\n",
    "        2.309778795006449,\n",
    "        3.002342870933531,\n",
    "        4.3425596543567,\n",
    "        6.027380459922358\n",
    "    ]\n",
    "\n",
    "        \n",
    "conf = Conf()\n",
    "print(conf)\n",
    "environment = jinja2.Environment()\n",
    "mc = conf.llm_map[conf.llm_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e55ac97c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:14:37.101166Z",
     "iopub.status.busy": "2024-07-02T15:14:37.100817Z",
     "iopub.status.idle": "2024-07-02T15:14:37.112790Z",
     "shell.execute_reply": "2024-07-02T15:14:37.111970Z"
    },
    "papermill": {
     "duration": 0.022096,
     "end_time": "2024-07-02T15:14:37.114864",
     "exception": false,
     "start_time": "2024-07-02T15:14:37.092768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "v1_template = environment.from_string(\n",
    "\"\"\"You are a teacher grading a student's essay. Assign a score on a scale of 1 to 6 based on the following rubric. A score of 6 indicates clear and consistent mastery with minor errors, showcasing insightful development of a viewpoint, outstanding critical thinking, strong use of appropriate examples and evidence, well-organized structure with coherence and smooth progression of ideas, skillful language use with varied vocabulary and sentence structure, and minimal errors in grammar, usage, and mechanics. Scores decrease with occasional errors (score of 5), lapses in quality (score of 4), weaknesses in critical thinking and organization (score of 3), serious flaws in viewpoint and coherence (score of 2), and fundamental errors hindering meaning (score of 1).\n",
    "In your response, output only the score without explanation.\n",
    "[ESSAY] {{ essay }} [/ESSAY]\n",
    "\"\"\"\n",
    ")\n",
    "v2_template = environment.from_string(\n",
    "\"\"\"You are a teacher grading a student's essay. Assign a score on a scale of 1 to 6 based on the following rubric. A score of 6 indicates clear and consistent mastery with minor errors, showcasing insightful development of a viewpoint, outstanding critical thinking, strong use of appropriate examples and evidence, well-organized structure with coherence and smooth progression of ideas, skillful language use with varied vocabulary and sentence structure, and minimal errors in grammar, usage, and mechanics. Scores decrease with occasional errors (score of 5), lapses in quality (score of 4), weaknesses in critical thinking and organization (score of 3), serious flaws in viewpoint and coherence (score of 2), and fundamental errors hindering meaning (score of 1).\n",
    "Provide constructive feedback to improve the essay.\n",
    "[ESSAY] {{ essay }} [/ESSAY]\n",
    "\"\"\"\n",
    ")\n",
    "v3_template = environment.from_string(\n",
    "\"\"\"You are a teacher grading a student's essay. Assign a score on a scale of 1 to 6 based on the following rubric. A score of 6 indicates clear and consistent mastery with minor errors, showcasing insightful development of a viewpoint, outstanding critical thinking, strong use of appropriate examples and evidence, well-organized structure with coherence and smooth progression of ideas, skillful language use with varied vocabulary and sentence structure, and minimal errors in grammar, usage, and mechanics. Scores decrease with occasional errors (score of 5), lapses in quality (score of 4), weaknesses in critical thinking and organization (score of 3), serious flaws in viewpoint and coherence (score of 2), and fundamental errors hindering meaning (score of 1).\n",
    "In your response, state the score and areas for improvement.\n",
    "[ESSAY] {{ essay }} [/ESSAY]\n",
    "\"\"\"\n",
    ")\n",
    "template = v1_template\n",
    "max_new_tokens = 16\n",
    "if conf.template_version==2:\n",
    "    template = v2_template\n",
    "    max_new_tokens = 64\n",
    "if conf.template_version==3:\n",
    "    template = v3_template\n",
    "    max_new_tokens = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8945fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:14:37.129573Z",
     "iopub.status.busy": "2024-07-02T15:14:37.129308Z",
     "iopub.status.idle": "2024-07-02T15:14:37.135973Z",
     "shell.execute_reply": "2024-07-02T15:14:37.135155Z"
    },
    "papermill": {
     "duration": 0.016492,
     "end_time": "2024-07-02T15:14:37.138117",
     "exception": false,
     "start_time": "2024-07-02T15:14:37.121625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=0, Tesla P100-PCIE-16GB\n",
      "Mem Allocated: 0.0 GB\n",
      "Mem Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"device={i}, {torch.cuda.get_device_name(i)}\")\n",
    "        print('Mem Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n",
    "        print('Mem Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')\n",
    "else:\n",
    "    print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98751f56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:14:37.152994Z",
     "iopub.status.busy": "2024-07-02T15:14:37.152705Z",
     "iopub.status.idle": "2024-07-02T15:14:44.609876Z",
     "shell.execute_reply": "2024-07-02T15:14:44.609111Z"
    },
    "papermill": {
     "duration": 7.467011,
     "end_time": "2024-07-02T15:14:44.612128",
     "exception": false,
     "start_time": "2024-07-02T15:14:37.145117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "sys.path.append(str(conf.input_dir / \"sgcharts-ml/src\"))\n",
    "sys.path.append(str(conf.resource_dir / \"src\"))\n",
    "import scml\n",
    "from scml import nlp as snlp\n",
    "from scml import pandasx as pdx\n",
    "import lalaes2 as mylib\n",
    "from warnings import simplefilter \n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8464fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:14:44.628286Z",
     "iopub.status.busy": "2024-07-02T15:14:44.627514Z",
     "iopub.status.idle": "2024-07-02T15:14:44.672695Z",
     "shell.execute_reply": "2024-07-02T15:14:44.671663Z"
    },
    "papermill": {
     "duration": 0.05523,
     "end_time": "2024-07-02T15:14:44.674750",
     "exception": false,
     "start_time": "2024-07-02T15:14:44.619520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 395.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   essay_id   3 non-null      object\n",
      " 1   full_text  3 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 176.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(conf.comp_dir / \"test.csv\")\n",
    "basic = mylib.BasicPreprocessor()\n",
    "\n",
    "\n",
    "def preprocess_text(fn, col) -> Callable:\n",
    "    def inner(row) -> str:\n",
    "        return fn(row[col])\n",
    "    \n",
    "    return inner\n",
    "\n",
    "\n",
    "df[\"full_text\"] = df.progress_apply(preprocess_text(basic, \"full_text\"), axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba45afef",
   "metadata": {
    "papermill": {
     "duration": 0.008169,
     "end_time": "2024-07-02T15:14:44.690212",
     "exception": false,
     "start_time": "2024-07-02T15:14:44.682043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LLM generates critique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71aa0b01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:14:44.706250Z",
     "iopub.status.busy": "2024-07-02T15:14:44.705697Z",
     "iopub.status.idle": "2024-07-02T15:14:45.731242Z",
     "shell.execute_reply": "2024-07-02T15:14:45.730328Z"
    },
    "papermill": {
     "duration": 1.036857,
     "end_time": "2024-07-02T15:14:45.734366",
     "exception": false,
     "start_time": "2024-07-02T15:14:44.697509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GemmaTokenizerFast(name_or_path='/kaggle/input/gemma/transformers/1.1-2b-it/1', vocab_size=256000, model_max_length=8192, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<eos>', 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<bos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t5: AddedToken(\"<2mass>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t6: AddedToken(\"[@BOS@]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t7: AddedToken(\"<unused0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t8: AddedToken(\"<unused1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t9: AddedToken(\"<unused2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t10: AddedToken(\"<unused3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t11: AddedToken(\"<unused4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t12: AddedToken(\"<unused5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t13: AddedToken(\"<unused6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t14: AddedToken(\"<unused7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t15: AddedToken(\"<unused8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t16: AddedToken(\"<unused9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t17: AddedToken(\"<unused10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t18: AddedToken(\"<unused11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t19: AddedToken(\"<unused12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t20: AddedToken(\"<unused13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t21: AddedToken(\"<unused14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t22: AddedToken(\"<unused15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t23: AddedToken(\"<unused16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t24: AddedToken(\"<unused17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t25: AddedToken(\"<unused18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t26: AddedToken(\"<unused19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t27: AddedToken(\"<unused20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t28: AddedToken(\"<unused21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t29: AddedToken(\"<unused22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t30: AddedToken(\"<unused23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t31: AddedToken(\"<unused24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t32: AddedToken(\"<unused25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t33: AddedToken(\"<unused26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t34: AddedToken(\"<unused27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t35: AddedToken(\"<unused28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t36: AddedToken(\"<unused29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t37: AddedToken(\"<unused30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t38: AddedToken(\"<unused31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t39: AddedToken(\"<unused32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t40: AddedToken(\"<unused33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t41: AddedToken(\"<unused34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t42: AddedToken(\"<unused35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t43: AddedToken(\"<unused36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t44: AddedToken(\"<unused37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t45: AddedToken(\"<unused38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t46: AddedToken(\"<unused39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t47: AddedToken(\"<unused40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t48: AddedToken(\"<unused41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t49: AddedToken(\"<unused42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t50: AddedToken(\"<unused43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t51: AddedToken(\"<unused44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t52: AddedToken(\"<unused45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t53: AddedToken(\"<unused46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t54: AddedToken(\"<unused47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t55: AddedToken(\"<unused48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t56: AddedToken(\"<unused49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t57: AddedToken(\"<unused50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t58: AddedToken(\"<unused51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t59: AddedToken(\"<unused52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t60: AddedToken(\"<unused53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t61: AddedToken(\"<unused54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t62: AddedToken(\"<unused55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t63: AddedToken(\"<unused56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t64: AddedToken(\"<unused57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t65: AddedToken(\"<unused58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t66: AddedToken(\"<unused59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t67: AddedToken(\"<unused60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t68: AddedToken(\"<unused61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t69: AddedToken(\"<unused62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t70: AddedToken(\"<unused63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t71: AddedToken(\"<unused64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t72: AddedToken(\"<unused65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t73: AddedToken(\"<unused66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t74: AddedToken(\"<unused67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t75: AddedToken(\"<unused68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t76: AddedToken(\"<unused69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t77: AddedToken(\"<unused70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t78: AddedToken(\"<unused71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t79: AddedToken(\"<unused72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t80: AddedToken(\"<unused73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t81: AddedToken(\"<unused74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t82: AddedToken(\"<unused75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t83: AddedToken(\"<unused76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t84: AddedToken(\"<unused77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t85: AddedToken(\"<unused78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t86: AddedToken(\"<unused79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t87: AddedToken(\"<unused80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t88: AddedToken(\"<unused81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t89: AddedToken(\"<unused82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t90: AddedToken(\"<unused83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t91: AddedToken(\"<unused84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t92: AddedToken(\"<unused85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t93: AddedToken(\"<unused86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t94: AddedToken(\"<unused87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t95: AddedToken(\"<unused88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t96: AddedToken(\"<unused89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t97: AddedToken(\"<unused90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t98: AddedToken(\"<unused91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t99: AddedToken(\"<unused92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t100: AddedToken(\"<unused93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t101: AddedToken(\"<unused94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t102: AddedToken(\"<unused95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t103: AddedToken(\"<unused96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t104: AddedToken(\"<unused97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t105: AddedToken(\"<unused98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t106: AddedToken(\"<start_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t107: AddedToken(\"<end_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t108: AddedToken(\"\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t109: AddedToken(\"\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t110: AddedToken(\"\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t111: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t112: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t113: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t114: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t115: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t116: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t117: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t118: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t119: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t120: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t121: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t122: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t123: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t124: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t125: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t126: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t127: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t128: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t129: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t130: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t131: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t132: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t133: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t134: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t135: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t136: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t137: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t138: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t139: AddedToken(\"▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t140: AddedToken(\"▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t141: AddedToken(\"▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t142: AddedToken(\"▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t143: AddedToken(\"▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t144: AddedToken(\"▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t145: AddedToken(\"▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t146: AddedToken(\"▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t147: AddedToken(\"▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t148: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t149: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t150: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t152: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t153: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t154: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t155: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t156: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t157: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t158: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t159: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t160: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t161: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t162: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t163: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t164: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t165: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t166: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t167: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t168: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t169: AddedToken(\"<table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t170: AddedToken(\"<caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t171: AddedToken(\"<thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t172: AddedToken(\"<tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t173: AddedToken(\"<tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t174: AddedToken(\"<tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t175: AddedToken(\"<th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t176: AddedToken(\"<td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t177: AddedToken(\"</table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t178: AddedToken(\"</caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t179: AddedToken(\"</thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t180: AddedToken(\"</tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t181: AddedToken(\"</tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t182: AddedToken(\"</tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t183: AddedToken(\"</th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t184: AddedToken(\"</td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t185: AddedToken(\"<h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t186: AddedToken(\"<h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t187: AddedToken(\"<h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t188: AddedToken(\"<h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t189: AddedToken(\"<h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t190: AddedToken(\"<h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t191: AddedToken(\"<blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t192: AddedToken(\"</h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t193: AddedToken(\"</h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t194: AddedToken(\"</h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t195: AddedToken(\"</h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t196: AddedToken(\"</h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t197: AddedToken(\"</h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t198: AddedToken(\"</blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t199: AddedToken(\"<strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200: AddedToken(\"<em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t201: AddedToken(\"<b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t202: AddedToken(\"<i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t203: AddedToken(\"<u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t204: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t205: AddedToken(\"<sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t206: AddedToken(\"<sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t207: AddedToken(\"<code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t208: AddedToken(\"</strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t209: AddedToken(\"</em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t210: AddedToken(\"</b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t211: AddedToken(\"</i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t212: AddedToken(\"</u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t213: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t214: AddedToken(\"</sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t215: AddedToken(\"</sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t216: AddedToken(\"</code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "}\n",
      "model_input_names=['input_ids', 'attention_mask']\n",
      "pad_token_id=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(mc.directory, model_max_length=mc.model_max_length)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(f\"\"\"{tokenizer}\n",
    "model_input_names={tokenizer.model_input_names}\n",
    "pad_token_id={tokenizer.pad_token_id}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "577e832c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:14:45.753106Z",
     "iopub.status.busy": "2024-07-02T15:14:45.752716Z",
     "iopub.status.idle": "2024-07-02T15:15:20.291797Z",
     "shell.execute_reply": "2024-07-02T15:15:20.290679Z"
    },
    "papermill": {
     "duration": 34.54999,
     "end_time": "2024-07-02T15:15:20.293723",
     "exception": false,
     "start_time": "2024-07-02T15:14:45.743733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load fp16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a34e582aae471e949b12f2965d4671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.07 s, sys: 4.67 s, total: 10.7 s\n",
      "Wall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# https://huggingface.co/blog/4bit-transformers-bitsandbytes\n",
    "# https://huggingface.co/docs/transformers/v4.38.1/en/quantization#compute-data-type\n",
    "# from qlora paper:\n",
    "# 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights\n",
    "if mc.load_in_dtype==\"q4\":\n",
    "    print(\"load 4bit\")\n",
    "    model = ModelForCausalLM.from_pretrained(\n",
    "        mc.directory,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_use_double_quant=True,  # Uses a second quantization after the first one to save an additional 0.4 bits per parameter\n",
    "        )\n",
    "    )\n",
    "elif mc.load_in_dtype==\"q8\":\n",
    "    print(\"load 8bit\")\n",
    "    model = ModelForCausalLM.from_pretrained(\n",
    "        mc.directory,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "        )\n",
    "    )\n",
    "elif mc.load_in_dtype==\"fp16\":\n",
    "    print(\"load fp16\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        mc.directory,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "        revision=\"float16\",\n",
    "    )\n",
    "else:\n",
    "    print(\"load auto\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        mc.directory,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1f1f87e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:15:20.312331Z",
     "iopub.status.busy": "2024-07-02T15:15:20.312050Z",
     "iopub.status.idle": "2024-07-02T15:15:20.319163Z",
     "shell.execute_reply": "2024-07-02T15:15:20.318264Z"
    },
    "papermill": {
     "duration": 0.018544,
     "end_time": "2024-07-02T15:15:20.321129",
     "exception": false,
     "start_time": "2024-07-02T15:15:20.302585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GemmaForCausalLM(\n",
      "  (model): GemmaModel(\n",
      "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-17): 18 x GemmaDecoderLayer(\n",
      "        (self_attn): GemmaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): GemmaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): GemmaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
      "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
      "          (act_fn): PytorchGELUTanh()\n",
      "        )\n",
      "        (input_layernorm): GemmaRMSNorm()\n",
      "        (post_attention_layernorm): GemmaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): GemmaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
      ")\n",
      "GemmaConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/gemma/transformers/1.1-2b-it/1\",\n",
      "  \"architectures\": [\n",
      "    \"GemmaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"head_dim\": 256,\n",
      "  \"hidden_act\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 16384,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"gemma\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 18,\n",
      "  \"num_key_value_heads\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 256000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b182f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:15:20.339360Z",
     "iopub.status.busy": "2024-07-02T15:15:20.339098Z",
     "iopub.status.idle": "2024-07-02T15:15:31.451319Z",
     "shell.execute_reply": "2024-07-02T15:15:31.450312Z"
    },
    "papermill": {
     "duration": 11.124245,
     "end_time": "2024-07-02T15:15:31.453942",
     "exception": false,
     "start_time": "2024-07-02T15:15:20.329697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:11<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "def critique(row) -> str:\n",
    "    \"\"\"Inference method and response extraction based on https://huggingface.co/Qwen/Qwen2-7B-Instruct\"\"\"\n",
    "    prompt = template.render(essay=str(row[\"full_text\"])[:mc.char_limit])\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    model_inputs = tokenizer(text, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    model_outputs = model.generate(\n",
    "        **model_inputs, \n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        #temperature=3.0,\n",
    "        #top_p=0.95,\n",
    "        #top_k=100,\n",
    "        repetition_penalty=1.1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, model_outputs)]\n",
    "    res = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    res = basic(res)\n",
    "    if len(res)==1 and res.isdigit():\n",
    "        res = f\"SCORE OF {res}\"\n",
    "    return res\n",
    "\n",
    "\n",
    "df[\"critique\"] = df.progress_apply(critique, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2601400e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:15:31.473687Z",
     "iopub.status.busy": "2024-07-02T15:15:31.473374Z",
     "iopub.status.idle": "2024-07-02T15:15:31.480169Z",
     "shell.execute_reply": "2024-07-02T15:15:31.479324Z"
    },
    "papermill": {
     "duration": 0.018807,
     "end_time": "2024-07-02T15:15:31.482055",
     "exception": false,
     "start_time": "2024-07-02T15:15:31.463248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**Score: 5** **Areas for Improvement:** * **Critical Thinking:** Lacks deeper analysis and critique of the text. * **Organization:** Paragraphs lack smooth transitions and logical flow. * **Vocabulary:** Limited and repetitive use of words. * **Grammar and Usage:** Minor grammatical errors and typos. **Strengths:** * Clear and concise writing style * Relevant and informative content * Emphasis on sustainable practices',\n",
       " '**Score: 5** **Areas for Improvement:** * **Critical Thinking and Organization:** Lacks deeper analysis and justification of claims. * **Language Use:** Some sentences are repetitive or lack variety. * **Grammar and Mechanics:** Minor grammatical errors and typos detract from clarity. **Strengths:** * Clear and concise introduction that states the main point early on. * Provides specific examples and evidence to support arguments. * Uses relatable examples from Earth to illustrate points.',\n",
       " \"**Score: 5** **Areas for Improvement:** * **Critical Thinking:** Lacks deeper analysis and evaluation of the potential risks and drawbacks of new technologies. * **Organization:** Paragraphs lack smooth transitions and logical flow, making it difficult to follow the author's train of thought. * **Language Use:** Vocabulary is limited and repetitive, and sentence structure is somewhat monotonous. * **Grammar and Mechanics:** Minor grammatical errors and typos detract from clarity and professionalism. **Strengths:** * Clear and concise writing style * Adequate use of supporting evidence * Relatively good organization and main points are addressed\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"critique\"].head().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "035a2898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:15:31.501468Z",
     "iopub.status.busy": "2024-07-02T15:15:31.501176Z",
     "iopub.status.idle": "2024-07-02T15:15:31.958389Z",
     "shell.execute_reply": "2024-07-02T15:15:31.957463Z"
    },
    "papermill": {
     "duration": 0.469406,
     "end_time": "2024-07-02T15:15:31.960552",
     "exception": false,
     "start_time": "2024-07-02T15:15:31.491146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ac6da",
   "metadata": {
    "papermill": {
     "duration": 0.009217,
     "end_time": "2024-07-02T15:15:31.979458",
     "exception": false,
     "start_time": "2024-07-02T15:15:31.970241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encoder Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd5dc512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:15:31.999772Z",
     "iopub.status.busy": "2024-07-02T15:15:31.999122Z",
     "iopub.status.idle": "2024-07-02T15:15:47.129225Z",
     "shell.execute_reply": "2024-07-02T15:15:47.128198Z"
    },
    "papermill": {
     "duration": 15.142556,
     "end_time": "2024-07-02T15:15:47.131350",
     "exception": false,
     "start_time": "2024-07-02T15:15:31.988794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits (3,)\n"
     ]
    }
   ],
   "source": [
    "mc = conf.models[0]\n",
    "tokenizer = AutoTokenizer.from_pretrained(mc.directory, model_max_length=mc.model_max_length)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(mc.directory)\n",
    "logits = mylib.predict_holistic_score(\n",
    "    ds=mylib.Aes2Dataset(\n",
    "        tokenizer=tokenizer,\n",
    "        critiques=df[\"critique\"].tolist(),\n",
    "        texts=df[\"full_text\"].tolist(),\n",
    "    ),\n",
    "    model=model,\n",
    "    batch_size=mc.batch_size,\n",
    "    device=device,\n",
    ")\n",
    "print(f\"logits {logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8142f12d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:15:47.152522Z",
     "iopub.status.busy": "2024-07-02T15:15:47.151927Z",
     "iopub.status.idle": "2024-07-02T15:15:47.176734Z",
     "shell.execute_reply": "2024-07-02T15:15:47.175670Z"
    },
    "papermill": {
     "duration": 0.037504,
     "end_time": "2024-07-02T15:15:47.178762",
     "exception": false,
     "start_time": "2024-07-02T15:15:47.141258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   essay_id  3 non-null      object\n",
      " 1   score     3 non-null      int8  \n",
      "dtypes: int8(1), object(1)\n",
      "memory usage: 155.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "y_pred = pd.cut(\n",
    "    x=logits,\n",
    "    bins=[-np.inf] + conf.thresholds + [np.inf], \n",
    "    labels=mylib.Aes2Dataset.HOLISTIC_SCORE_LABELS,\n",
    ")\n",
    "df[\"score\"] = y_pred.astype(np.int8)\n",
    "cols = [\"essay_id\", \"score\"]\n",
    "sub = df[cols]\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb28d9eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:15:47.199192Z",
     "iopub.status.busy": "2024-07-02T15:15:47.198860Z",
     "iopub.status.idle": "2024-07-02T15:15:47.209591Z",
     "shell.execute_reply": "2024-07-02T15:15:47.208649Z"
    },
    "papermill": {
     "duration": 0.023039,
     "end_time": "2024-07-02T15:15:47.211483",
     "exception": false,
     "start_time": "2024-07-02T15:15:47.188444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  score\n",
       "0  000d118      3\n",
       "1  000fe60      3\n",
       "2  001ab80      4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a299a",
   "metadata": {
    "papermill": {
     "duration": 0.009981,
     "end_time": "2024-07-02T15:15:47.231992",
     "exception": false,
     "start_time": "2024-07-02T15:15:47.222011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e40d595e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:15:47.253475Z",
     "iopub.status.busy": "2024-07-02T15:15:47.253176Z",
     "iopub.status.idle": "2024-07-02T15:15:47.256988Z",
     "shell.execute_reply": "2024-07-02T15:15:47.256123Z"
    },
    "papermill": {
     "duration": 0.016906,
     "end_time": "2024-07-02T15:15:47.259160",
     "exception": false,
     "start_time": "2024-07-02T15:15:47.242254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ef2f46d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:15:47.280311Z",
     "iopub.status.busy": "2024-07-02T15:15:47.280060Z",
     "iopub.status.idle": "2024-07-02T15:15:47.284705Z",
     "shell.execute_reply": "2024-07-02T15:15:47.283842Z"
    },
    "papermill": {
     "duration": 0.01733,
     "end_time": "2024-07-02T15:15:47.286542",
     "exception": false,
     "start_time": "2024-07-02T15:15:47.269212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code for running LLM batch inference\n",
    "#prompts = [template.render(essay=text[:conf.char_limit]) for text in df[\"full_text\"]]\n",
    "#out = []\n",
    "#i=0\n",
    "#bsz=conf.llm_model.batch_size\n",
    "#while i<len(prompts):\n",
    "#    inputs = tokenizer(\n",
    "#        prompts[i:i+bsz],\n",
    "#        truncation=True,\n",
    "#        padding=\"max_length\",\n",
    "#        return_tensors=\"pt\",\n",
    "#    ).to(device)\n",
    "#    outputs = llm.generate(\n",
    "#        **inputs, \n",
    "#        max_new_tokens=256,\n",
    "#        do_sample=True,\n",
    "#        temperature=1.0,\n",
    "#        top_p=0.95,\n",
    "#        top_k=40,\n",
    "#        repetition_penalty=1.1,\n",
    "#        pad_token_id=tokenizer.eos_token_id,\n",
    "#    )\n",
    "#    generated_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "#    for generated_text in generated_texts:\n",
    "#        parts = generated_text.split(\"[/INST]\")\n",
    "#        if len(parts)==2:\n",
    "#            generated_text = parts[1]\n",
    "#            generated_text = basic(generated_text)\n",
    "#        else:\n",
    "#            generated_text = \"None\"\n",
    "#        out.append(generated_text)\n",
    "#    i+=bsz\n",
    "#df[\"prompt\"] = out"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 4827409,
     "sourceId": 8159746,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 960933,
     "sourceId": 8426245,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3215198,
     "sourceId": 8715383,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5188394,
     "sourceId": 8822563,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 4761,
     "sourceId": 5994,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 8658,
     "sourceId": 10716,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 22003,
     "sourceId": 26140,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 28079,
     "sourceId": 33547,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 52038,
     "sourceId": 62308,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 134.237462,
   "end_time": "2024-07-02T15:15:50.365636",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-02T15:13:36.128174",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03778b44cc4648259d65156ef8776142": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "07be808b4501471ebfeb390e2119a9e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "25b00ab7301b4082996900fc0e5da87e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "42a34e582aae471e949b12f2965d4671": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c10bfbad25b34b5790ceda5d15e9b875",
        "IPY_MODEL_88583fd5403e4aadbd1cabc8468a7384",
        "IPY_MODEL_c7c42df221e441558c9cc43740632278"
       ],
       "layout": "IPY_MODEL_bb07d79aca264b8e835d22a1cf513347"
      }
     },
     "88583fd5403e4aadbd1cabc8468a7384": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_de4291709f9c4271804f906684bfc40e",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_07be808b4501471ebfeb390e2119a9e2",
       "value": 2.0
      }
     },
     "9d198dafe5e843d2ad7cf0d21d248b33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a86a15c0c9764a35998e3550fab4ef3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bb07d79aca264b8e835d22a1cf513347": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c10bfbad25b34b5790ceda5d15e9b875": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_25b00ab7301b4082996900fc0e5da87e",
       "placeholder": "​",
       "style": "IPY_MODEL_a86a15c0c9764a35998e3550fab4ef3c",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "c7c42df221e441558c9cc43740632278": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9d198dafe5e843d2ad7cf0d21d248b33",
       "placeholder": "​",
       "style": "IPY_MODEL_03778b44cc4648259d65156ef8776142",
       "value": " 2/2 [00:34&lt;00:00, 14.15s/it]"
      }
     },
     "de4291709f9c4271804f906684bfc40e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
