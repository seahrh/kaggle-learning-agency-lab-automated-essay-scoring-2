{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef26d94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:31:32.921362Z",
     "iopub.status.busy": "2024-06-17T04:31:32.920837Z",
     "iopub.status.idle": "2024-06-17T04:32:46.017177Z",
     "shell.execute_reply": "2024-06-17T04:32:46.015652Z"
    },
    "papermill": {
     "duration": 73.110301,
     "end_time": "2024-06-17T04:32:46.021115",
     "exception": false,
     "start_time": "2024-06-17T04:31:32.910814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pip-wheels/scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "Successfully installed scikit-learn-1.5.0\r\n",
      "Processing /kaggle/input/pip-wheels/pyphen-0.15.0-py3-none-any.whl\r\n",
      "Installing collected packages: pyphen\r\n",
      "Successfully installed pyphen-0.15.0\r\n",
      "Processing /kaggle/input/pip-wheels/textstat-0.7.3-py3-none-any.whl\r\n",
      "Installing collected packages: textstat\r\n",
      "Successfully installed textstat-0.7.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --no-deps --force-reinstall /kaggle/input/pip-wheels/scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install --upgrade --no-deps --force-reinstall /kaggle/input/pip-wheels/pyphen-0.15.0-py3-none-any.whl\n",
    "!pip install --upgrade --no-deps --force-reinstall /kaggle/input/pip-wheels/textstat-0.7.3-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef45f9a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-17T04:32:46.041470Z",
     "iopub.status.busy": "2024-06-17T04:32:46.041072Z",
     "iopub.status.idle": "2024-06-17T04:32:55.561807Z",
     "shell.execute_reply": "2024-06-17T04:32:55.560249Z"
    },
    "papermill": {
     "duration": 9.534449,
     "end_time": "2024-06-17T04:32:55.564453",
     "exception": false,
     "start_time": "2024-06-17T04:32:46.030004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==1.5.0, textstat==(0, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "import textstat\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, NamedTuple, Callable, Iterable, Set, Optional, Any\n",
    "print(f\"scikit-learn=={sklearn.__version__}, textstat=={textstat.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3874ded8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:32:55.584850Z",
     "iopub.status.busy": "2024-06-17T04:32:55.584134Z",
     "iopub.status.idle": "2024-06-17T04:32:55.596111Z",
     "shell.execute_reply": "2024-06-17T04:32:55.594880Z"
    },
    "papermill": {
     "duration": 0.025314,
     "end_time": "2024-06-17T04:32:55.598469",
     "exception": false,
     "start_time": "2024-06-17T04:32:55.573155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conf(debug=False, input_dir=PosixPath('/kaggle/input'), comp_dir=PosixPath('/kaggle/input/learning-agency-lab-automated-essay-scoring-2'), temp_dir=PosixPath('/kaggle/temp'), working_dir=PosixPath('/kaggle/working'), resource_dir=PosixPath('/kaggle/input/lib-lalaes2/lalaes2-0.1'), data_dir=PosixPath('/kaggle/input/lib-lalaes2/lalaes2-0.1/input'), lgb_model_file=PosixPath('/kaggle/input/lib-lalaes2/lalaes2-0.1/models/lgb/20240617_121519/lgb.txt'), base_models=[ModelConf(name='deberta_base', directory=PosixPath('/kaggle/input/lib-lalaes2/lalaes2-0.1/models/aes2/deberta_v3_base/20240615_063400'), model_max_length=512, batch_size=32)], thresholds=[1.5679287510412498, 2.5150679100687494, 3.4973218989187504, 4.4458222753237475, 5.526982087151248])\n"
     ]
    }
   ],
   "source": [
    "class ModelConf(NamedTuple):\n",
    "    name: str\n",
    "    directory: Path\n",
    "    model_max_length: int\n",
    "    batch_size: int\n",
    "        \n",
    "\n",
    "class Conf(NamedTuple):\n",
    "    debug: bool = False  \n",
    "    input_dir: Path = Path(\"/kaggle/input\")\n",
    "    comp_dir: Path = input_dir / \"learning-agency-lab-automated-essay-scoring-2\"\n",
    "    temp_dir: Path = Path('/kaggle/temp')\n",
    "    # write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "    working_dir: Path = Path('/kaggle/working')\n",
    "    resource_dir: Path = input_dir / \"lib-lalaes2/lalaes2-0.1\"\n",
    "    data_dir: Path = resource_dir / \"input\"\n",
    "    lgb_model_file: Path = resource_dir / \"models/lgb/20240617_121519/lgb.txt\" \n",
    "    base_models: List[ModelConf] = [\n",
    "        ModelConf(\n",
    "            name=\"deberta_base\",\n",
    "            directory=resource_dir / \"models/aes2/deberta_v3_base/20240615_063400\",\n",
    "            model_max_length=512,\n",
    "            batch_size=32,\n",
    "        ),\n",
    "    ]\n",
    "    thresholds: List[float] = [1.5679287510412498, 2.5150679100687494, 3.4973218989187504, 4.4458222753237475, 5.526982087151248]\n",
    "\n",
    "conf = Conf()\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19799406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:32:55.618181Z",
     "iopub.status.busy": "2024-06-17T04:32:55.617787Z",
     "iopub.status.idle": "2024-06-17T04:32:55.627763Z",
     "shell.execute_reply": "2024-06-17T04:32:55.625380Z"
    },
    "papermill": {
     "duration": 0.023202,
     "end_time": "2024-06-17T04:32:55.630911",
     "exception": false,
     "start_time": "2024-06-17T04:32:55.607709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"device={i}, {torch.cuda.get_device_name(i)}\")\n",
    "        print('Mem Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n",
    "        print('Mem Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')\n",
    "else:\n",
    "    print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71144911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:32:55.651552Z",
     "iopub.status.busy": "2024-06-17T04:32:55.651157Z",
     "iopub.status.idle": "2024-06-17T04:33:03.586637Z",
     "shell.execute_reply": "2024-06-17T04:33:03.585345Z"
    },
    "papermill": {
     "duration": 7.949612,
     "end_time": "2024-06-17T04:33:03.589804",
     "exception": false,
     "start_time": "2024-06-17T04:32:55.640192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "sys.path.append(str(conf.input_dir / \"sgcharts-ml/src\"))\n",
    "sys.path.append(str(conf.resource_dir / \"src\"))\n",
    "import scml\n",
    "from scml import nlp as snlp\n",
    "from scml import pandasx as pdx\n",
    "import lalaes2 as mylib\n",
    "from warnings import simplefilter \n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506407b8",
   "metadata": {
    "papermill": {
     "duration": 0.008749,
     "end_time": "2024-06-17T04:33:03.607573",
     "exception": false,
     "start_time": "2024-06-17T04:33:03.598824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f24aa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:33:03.628993Z",
     "iopub.status.busy": "2024-06-17T04:33:03.627748Z",
     "iopub.status.idle": "2024-06-17T04:33:03.692352Z",
     "shell.execute_reply": "2024-06-17T04:33:03.691087Z"
    },
    "papermill": {
     "duration": 0.079805,
     "end_time": "2024-06-17T04:33:03.696441",
     "exception": false,
     "start_time": "2024-06-17T04:33:03.616636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 281.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   essay_id    3 non-null      object\n",
      " 1   full_text   3 non-null      object\n",
      " 2   clean_text  3 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 200.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(conf.comp_dir / \"test.csv\")\n",
    "basic = mylib.BasicPreprocessor()\n",
    "\n",
    "\n",
    "def preprocess_text(fn, col) -> Callable:\n",
    "    def inner(row) -> str:\n",
    "        return fn(row[col])\n",
    "    \n",
    "    return inner\n",
    "\n",
    "\n",
    "text_col = \"clean_text\"\n",
    "df[text_col] = df.progress_apply(preprocess_text(basic, \"full_text\"), axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e3b7c",
   "metadata": {
    "papermill": {
     "duration": 0.009047,
     "end_time": "2024-06-17T04:33:03.716063",
     "exception": false,
     "start_time": "2024-06-17T04:33:03.707016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf579c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:33:03.736947Z",
     "iopub.status.busy": "2024-06-17T04:33:03.736537Z",
     "iopub.status.idle": "2024-06-17T04:33:03.741767Z",
     "shell.execute_reply": "2024-06-17T04:33:03.740677Z"
    },
    "papermill": {
     "duration": 0.018836,
     "end_time": "2024-06-17T04:33:03.744239",
     "exception": false,
     "start_time": "2024-06-17T04:33:03.725403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b630dd",
   "metadata": {
    "papermill": {
     "duration": 0.009445,
     "end_time": "2024-06-17T04:33:03.763458",
     "exception": false,
     "start_time": "2024-06-17T04:33:03.754013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Base Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab7bd72f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:33:03.783975Z",
     "iopub.status.busy": "2024-06-17T04:33:03.783542Z",
     "iopub.status.idle": "2024-06-17T04:33:17.388142Z",
     "shell.execute_reply": "2024-06-17T04:33:17.386507Z"
    },
    "papermill": {
     "duration": 13.618038,
     "end_time": "2024-06-17T04:33:17.390933",
     "exception": false,
     "start_time": "2024-06-17T04:33:03.772895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deberta_base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2.350891\n",
       "1    2.673539\n",
       "2    4.360243\n",
       "Name: deberta_base, dtype: float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for mc in conf.base_models:\n",
    "    print(mc.name)\n",
    "    df[mc.name] = mylib.predict_holistic_score(\n",
    "        ds=mylib.Aes2Dataset(\n",
    "            tokenizer=AutoTokenizer.from_pretrained(mc.directory, model_max_length=mc.model_max_length),\n",
    "            texts=df[text_col].tolist(),\n",
    "        ),\n",
    "        model=AutoModelForSequenceClassification.from_pretrained(mc.directory),\n",
    "        batch_size=mc.batch_size,\n",
    "        device=device,\n",
    "        progress_bar=False,\n",
    "    )\n",
    "    features.append(mc.name)\n",
    "df[mc.name].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39ff69",
   "metadata": {
    "papermill": {
     "duration": 0.010921,
     "end_time": "2024-06-17T04:33:17.413085",
     "exception": false,
     "start_time": "2024-06-17T04:33:17.402164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Character & Word-level Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d803cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:33:17.435426Z",
     "iopub.status.busy": "2024-06-17T04:33:17.434389Z",
     "iopub.status.idle": "2024-06-17T04:33:17.439230Z",
     "shell.execute_reply": "2024-06-17T04:33:17.438231Z"
    },
    "papermill": {
     "duration": 0.018718,
     "end_time": "2024-06-17T04:33:17.441668",
     "exception": false,
     "start_time": "2024-06-17T04:33:17.422950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#col = \"cw_len\"\n",
    "#df[col] = df[text_col].str.len()\n",
    "#features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1222ceee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:33:17.462804Z",
     "iopub.status.busy": "2024-06-17T04:33:17.462369Z",
     "iopub.status.idle": "2024-06-17T04:33:22.678172Z",
     "shell.execute_reply": "2024-06-17T04:33:22.676976Z"
    },
    "papermill": {
     "duration": 5.229396,
     "end_time": "2024-06-17T04:33:22.680695",
     "exception": false,
     "start_time": "2024-06-17T04:33:17.451299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cw_stopword_frac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1586.55it/s]\n"
     ]
    }
   ],
   "source": [
    "def digit_frac(row) -> float:\n",
    "    return mylib.digit_frac(row[text_col])\n",
    "\n",
    "\n",
    "def letter_frac(row) -> float:\n",
    "    return mylib.letter_frac(row[text_col])\n",
    "\n",
    "\n",
    "def space_frac(row) -> float:\n",
    "    return mylib.space_frac(row[text_col])\n",
    "\n",
    "\n",
    "def punc_frac(row) -> float:\n",
    "    return mylib.punc_frac(row[text_col])\n",
    "\n",
    "\n",
    "def upper_frac(row) -> float:\n",
    "    return mylib.upper_frac(row[text_col])\n",
    "\n",
    "\n",
    "def repeat_char_frac(row) -> float:\n",
    "    return mylib.repeat_char_frac(row[text_col])\n",
    "\n",
    "\n",
    "def repeat_substring_frac(row) -> float:\n",
    "    return mylib.repeat_substring_frac(row[text_col])\n",
    "\n",
    "\n",
    "def unique_word_frac(row) -> float:\n",
    "    return mylib.unique_word_frac(row[text_col])\n",
    "\n",
    "\n",
    "sf = mylib.StopwordFraction()\n",
    "\n",
    "\n",
    "def stopword_frac(row) -> float:\n",
    "    return sf(row[text_col])\n",
    "\n",
    "\n",
    "\n",
    "cw_fns: List[Tuple[str, Callable]] = [\n",
    "    #(\"cw_digit_frac\", digit_frac),\n",
    "    #(\"cw_letter_frac\", letter_frac),\n",
    "    #(\"cw_space_frac\", space_frac),\n",
    "    #(\"cw_punc_frac\", punc_frac),\n",
    "    #(\"cw_upper_frac\", upper_frac),\n",
    "    #(\"cw_repeat_char_frac\", repeat_char_frac),\n",
    "    #(\"cw_repeat_substring_frac\", repeat_substring_frac),\n",
    "    #(\"cw_unique_word_frac\", unique_word_frac),\n",
    "    (\"cw_stopword_frac\", stopword_frac),\n",
    "]   \n",
    "for col, fn in cw_fns:\n",
    "    print(col)\n",
    "    df[col] = df.progress_apply(fn, axis=1)\n",
    "    features.append(col)\n",
    "df[features] = df[features].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40911715",
   "metadata": {
    "papermill": {
     "duration": 0.00998,
     "end_time": "2024-06-17T04:33:22.700697",
     "exception": false,
     "start_time": "2024-06-17T04:33:22.690717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Textstat Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f6e5ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:33:22.722761Z",
     "iopub.status.busy": "2024-06-17T04:33:22.722292Z",
     "iopub.status.idle": "2024-06-17T04:33:22.907004Z",
     "shell.execute_reply": "2024-06-17T04:33:22.905774Z"
    },
    "papermill": {
     "duration": 0.19896,
     "end_time": "2024-06-17T04:33:22.909579",
     "exception": false,
     "start_time": "2024-06-17T04:33:22.710619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_syllable_count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 118.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_lexicon_count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1818.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_sentence_count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1205.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_syllables_per_word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2642.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_syllables_per_sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2696.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_words_per_sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2259.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_flesch_reading_ease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2296.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_flesch_kincaid_grade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2225.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_gunning_fog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 233.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_smog_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 402.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_automated_readability_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1180.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_coleman_liau_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 948.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_linsear_write_formula\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 924.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_dale_chall_readability_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 533.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_text_standard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2109.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_mcalpine_eflaw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1316.07it/s]\n"
     ]
    }
   ],
   "source": [
    "def syllable_count(row) -> int:\n",
    "    return textstat.syllable_count(row[text_col])\n",
    "\n",
    "\n",
    "def lexicon_count(row) -> int:\n",
    "    return textstat.lexicon_count(row[text_col])\n",
    "\n",
    "\n",
    "def sentence_count(row) -> int:\n",
    "    return textstat.sentence_count(row[text_col])\n",
    "\n",
    "\n",
    "def syllables_per_word(row) -> float:\n",
    "    return row[\"ts_syllable_count\"] / (row[\"ts_lexicon_count\"] + 1)\n",
    "\n",
    "\n",
    "def syllables_per_sent(row) -> float:\n",
    "    return row[\"ts_syllable_count\"] / (row[\"ts_sentence_count\"] + 1)\n",
    "\n",
    "\n",
    "def words_per_sent(row) -> float:\n",
    "    return row[\"ts_lexicon_count\"] / (row[\"ts_sentence_count\"] + 1)\n",
    "\n",
    "\n",
    "def flesch_reading_ease(row) -> float:\n",
    "    return textstat.flesch_reading_ease(row[text_col])\n",
    "\n",
    "\n",
    "def flesch_kincaid_grade(row) -> float:\n",
    "    return textstat.flesch_kincaid_grade(row[text_col])\n",
    "\n",
    "\n",
    "def gunning_fog(row) -> float:\n",
    "    return textstat.gunning_fog(row[text_col])\n",
    "\n",
    "\n",
    "def smog_index(row) -> float:\n",
    "    return textstat.smog_index(row[text_col])\n",
    "\n",
    "\n",
    "def automated_readability_index(row) -> float:\n",
    "    return textstat.automated_readability_index(row[text_col])\n",
    "\n",
    "\n",
    "def coleman_liau_index(row) -> float:\n",
    "    return textstat.coleman_liau_index(row[text_col])\n",
    "\n",
    "\n",
    "def linsear_write_formula(row) -> float:\n",
    "    return textstat.linsear_write_formula(row[text_col])\n",
    "\n",
    "\n",
    "def dale_chall_readability_score(row) -> float:\n",
    "    return textstat.dale_chall_readability_score(row[text_col])\n",
    "\n",
    "\n",
    "def text_standard(row) -> float:\n",
    "    return textstat.text_standard(row[text_col], float_output=True)\n",
    "\n",
    "\n",
    "def mcalpine_eflaw(row) -> float:\n",
    "    return textstat.mcalpine_eflaw(row[text_col])\n",
    "\n",
    "\n",
    "textstat_fns: List[Tuple[str, Callable]] = [\n",
    "    (\"ts_syllable_count\", syllable_count),\n",
    "    (\"ts_lexicon_count\", lexicon_count),\n",
    "    (\"ts_sentence_count\", sentence_count),\n",
    "    (\"ts_syllables_per_word\", syllables_per_word),\n",
    "    (\"ts_syllables_per_sent\", syllables_per_sent),\n",
    "    (\"ts_words_per_sent\", words_per_sent),\n",
    "    (\"ts_flesch_reading_ease\", flesch_reading_ease),\n",
    "    (\"ts_flesch_kincaid_grade\", flesch_kincaid_grade),\n",
    "    (\"ts_gunning_fog\", gunning_fog),\n",
    "    (\"ts_smog_index\", smog_index),\n",
    "    (\"ts_automated_readability_index\", automated_readability_index),\n",
    "    (\"ts_coleman_liau_index\", coleman_liau_index),\n",
    "    (\"ts_linsear_write_formula\", linsear_write_formula),\n",
    "    (\"ts_dale_chall_readability_score\", dale_chall_readability_score),\n",
    "    (\"ts_text_standard\", text_standard),\n",
    "    (\"ts_mcalpine_eflaw\", mcalpine_eflaw),\n",
    "]    \n",
    "for col, fn in textstat_fns:\n",
    "    print(col)\n",
    "    df[col] = df.progress_apply(fn, axis=1)\n",
    "    if col.endswith(\"_count\"):\n",
    "        continue\n",
    "    features.append(col)\n",
    "df[features] = df[features].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3d350",
   "metadata": {
    "papermill": {
     "duration": 0.015961,
     "end_time": "2024-06-17T04:33:22.942298",
     "exception": false,
     "start_time": "2024-06-17T04:33:22.926337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Final Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1b92011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:33:22.977581Z",
     "iopub.status.busy": "2024-06-17T04:33:22.977172Z",
     "iopub.status.idle": "2024-06-17T04:33:23.031158Z",
     "shell.execute_reply": "2024-06-17T04:33:23.029521Z"
    },
    "papermill": {
     "duration": 0.075452,
     "end_time": "2024-06-17T04:33:23.033972",
     "exception": false,
     "start_time": "2024-06-17T04:33:22.958520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.12307912 1.2214806  1.12307912]\n",
      "CPU times: user 14.8 ms, sys: 3.58 ms, total: 18.3 ms\n",
      "Wall time: 47.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = lgb.Booster(model_file=conf.lgb_model_file)\n",
    "logits = model.predict(df[features])\n",
    "print(logits[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "502dfb7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:33:23.067815Z",
     "iopub.status.busy": "2024-06-17T04:33:23.067423Z",
     "iopub.status.idle": "2024-06-17T04:33:23.094390Z",
     "shell.execute_reply": "2024-06-17T04:33:23.093167Z"
    },
    "papermill": {
     "duration": 0.046802,
     "end_time": "2024-06-17T04:33:23.096947",
     "exception": false,
     "start_time": "2024-06-17T04:33:23.050145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   essay_id  3 non-null      object\n",
      " 1   score     3 non-null      int8  \n",
      "dtypes: int8(1), object(1)\n",
      "memory usage: 155.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "y_pred = pd.cut(\n",
    "    x=logits, \n",
    "    bins=[-np.inf] + conf.thresholds + [np.inf], \n",
    "    labels=mylib.Aes2Dataset.HOLISTIC_SCORE_LABELS,\n",
    ")\n",
    "df[\"score\"] = y_pred.astype(np.int8)\n",
    "cols = [\"essay_id\", \"score\"]\n",
    "sub = df[cols]\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e548416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:33:23.130954Z",
     "iopub.status.busy": "2024-06-17T04:33:23.130532Z",
     "iopub.status.idle": "2024-06-17T04:33:23.145197Z",
     "shell.execute_reply": "2024-06-17T04:33:23.144052Z"
    },
    "papermill": {
     "duration": 0.034998,
     "end_time": "2024-06-17T04:33:23.147897",
     "exception": false,
     "start_time": "2024-06-17T04:33:23.112899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  score\n",
       "0  000d118      1\n",
       "1  000fe60      1\n",
       "2  001ab80      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da076c87",
   "metadata": {
    "papermill": {
     "duration": 0.016147,
     "end_time": "2024-06-17T04:33:23.181103",
     "exception": false,
     "start_time": "2024-06-17T04:33:23.164956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46d2db14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T04:33:23.215463Z",
     "iopub.status.busy": "2024-06-17T04:33:23.215069Z",
     "iopub.status.idle": "2024-06-17T04:33:23.220272Z",
     "shell.execute_reply": "2024-06-17T04:33:23.219040Z"
    },
    "papermill": {
     "duration": 0.025307,
     "end_time": "2024-06-17T04:33:23.222732",
     "exception": false,
     "start_time": "2024-06-17T04:33:23.197425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 960933,
     "sourceId": 8426245,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3215198,
     "sourceId": 8684726,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5188394,
     "sourceId": 8708859,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 116.266877,
   "end_time": "2024-06-17T04:33:25.928767",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-17T04:31:29.661890",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
